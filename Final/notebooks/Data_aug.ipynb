{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test out data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# We import the data set from tensorflow and build the model there\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CLASS = [[\"c0\", \"Safe Driving\"], [\"c1\", \"Text\"], [\"c2\", \"Phone\"],\n",
    "         [\"c3\", \"Adjusting Radio\"], [\"c4\", \"Drinking\"],\n",
    "         [\"c5\", \"Reaching Behind\"], [\"c6\", \"Hair or Makeup\"],\n",
    "         [\"c7\", \"Talking to Passenger\"]]\n",
    "TEST_CLS = [os.path.join(os.getcwd(), \"../Data/Distracted Driver Dataset\", \"Combined\", \"test\", cls[0]) for cls in CLASS]\n",
    "TRAIN_CLS = [os.path.join(os.getcwd(), \"../Data/Distracted Driver Dataset\", \"Combined\", \"train\", cls[0]) for cls in CLASS]\n",
    "\n",
    "train_paths = []\n",
    "test_paths = []\n",
    "for cls in range(8):\n",
    "  for train_instance in os.listdir(TRAIN_CLS[cls]):\n",
    "    train_paths.append(os.path.join(TRAIN_CLS[cls], train_instance))\n",
    "  for test_instance in os.listdir(TEST_CLS[cls]):\n",
    "    test_paths.append(os.path.join(TEST_CLS[cls], test_instance))\n",
    "classes = []\n",
    "test_classes = []\n",
    "for cls in range(8):\n",
    "  for train_instance in os.listdir(TRAIN_CLS[cls]):\n",
    "    classes.append(cls)\n",
    "  for test_instance in os.listdir(TEST_CLS[cls]):\n",
    "    test_classes.append(cls)\n",
    "df = pd.DataFrame({\n",
    "  'filename': train_paths,\n",
    "  'class': classes\n",
    "})\n",
    "df_test = pd.DataFrame({\n",
    "  'filename': test_paths,\n",
    "  'class': test_classes\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for index, path in df.iterrows():\n",
    "    img_orig = cv2.imread(path[0], cv2.IMREAD_COLOR)\n",
    "    k = min(1.0, 1024/max(img_orig.shape[0], img_orig.shape[1]))\n",
    "    img = cv2.resize(img_orig, (100, 100), fx=k, fy=k, interpolation=cv2.INTER_LANCZOS4)\n",
    "    X_train.append(np.asarray(img/255))\n",
    "    Y_train.append(path[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10044, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_val, X_train_final, Y_val, Y_train_final = train_test_split(X_train, Y_train, test_size=0.8, stratify=Y_train, random_state=42)\n",
    "X_val = np.asarray(X_val)\n",
    "Y_val = np.asarray(Y_val)\n",
    "Y_val = np_utils.to_categorical(Y_val, 8)\n",
    "X_train_final = np.asarray(X_train_final)\n",
    "Y_train_final = np.asarray(Y_train_final)\n",
    "Y_train_final = np_utils.to_categorical(Y_train_final, 8)\n",
    "Y_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "for index, path in df_test.iterrows():\n",
    "    img_orig = cv2.imread(path[0], cv2.IMREAD_COLOR)\n",
    "    k = min(1.0, 1024/max(img_orig.shape[0], img_orig.shape[1]))\n",
    "    img = cv2.resize(img_orig, (100, 100), fx=k, fy=k, interpolation=cv2.INTER_LANCZOS4)\n",
    "    X_test.append(np.asarray(img/255))\n",
    "    Y_test.append(path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1923, 100, 100, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.asarray(X_test)\n",
    "Y_test = np.asarray(Y_test)\n",
    "Y_test = np_utils.to_categorical(Y_test, 8)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Layers of random image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\", seed=1, input_shape=(100, 100, 3)),\n",
    "    layers.RandomRotation(0.3, seed=1),\n",
    "    layers.RandomBrightness(0.1, value_range=(0.0, 1.0), seed=1),\n",
    "    layers.RandomContrast(0.2, seed=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_3 (Sequential)   (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 100, 100, 16)      448       \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 100, 100, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 34, 34, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 34, 34, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 34, 34, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 12, 12, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 12, 12, 48)        13872     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 12, 12, 48)       192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 4, 4, 48)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 6152      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,496\n",
      "Trainable params: 25,304\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    transform,\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(3, padding='same'),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(3, padding='same'),\n",
    "    layers.Conv2D(48, 3, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(3, padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(8, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "51/51 [==============================] - 57s 1s/step - loss: 3.0855 - accuracy: 0.1716 - val_loss: 5.1633 - val_accuracy: 0.2103\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 51s 1s/step - loss: 2.1483 - accuracy: 0.2026 - val_loss: 1.9858 - val_accuracy: 0.2071\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 52s 1s/step - loss: 2.0300 - accuracy: 0.2195 - val_loss: 1.9469 - val_accuracy: 0.2119\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 51s 998ms/step - loss: 1.9343 - accuracy: 0.2524 - val_loss: 1.9672 - val_accuracy: 0.2294\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 50s 984ms/step - loss: 1.8761 - accuracy: 0.2753 - val_loss: 2.0074 - val_accuracy: 0.2338\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 50s 983ms/step - loss: 1.8503 - accuracy: 0.2821 - val_loss: 1.8480 - val_accuracy: 0.2955\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 51s 1s/step - loss: 1.8140 - accuracy: 0.2938 - val_loss: 1.8416 - val_accuracy: 0.2871\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 51s 997ms/step - loss: 1.7977 - accuracy: 0.3043 - val_loss: 1.8051 - val_accuracy: 0.2879\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 51s 1s/step - loss: 1.7646 - accuracy: 0.3221 - val_loss: 1.8573 - val_accuracy: 0.2843\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 50s 987ms/step - loss: 1.7622 - accuracy: 0.3276 - val_loss: 1.7814 - val_accuracy: 0.3369\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor='accuracy', patience=2)\n",
    "]\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(X_train_final, Y_train_final, epochs=EPOCHS, batch_size=BATCH_SIZE,callbacks=callbacks_list, validation_data=(X_val, Y_val), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 2s 37ms/step - loss: 2.0468 - accuracy: 0.1997\n",
      "\n",
      "Accuracy on test data: 0.20\n",
      "\n",
      "Loss on test data: 2.05\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"\\nAccuracy on test data: %0.2f\" % score[1])\n",
    "print(\"\\nLoss on test data: %0.2f\" % score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 50, 50, 16)        448       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 50, 50, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 25, 25, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 13, 13, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 48)          13872     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4, 4, 48)         192       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 48)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 1544      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,888\n",
      "Trainable params: 20,696\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(16, 3, 2, padding='same', activation='relu', input_shape=(100, 100, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(padding='same'),\n",
    "    layers.Conv2D(32, 3, 2, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(padding='same'),\n",
    "    layers.Conv2D(48, 3, 2, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(8, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "51/51 [==============================] - 15s 256ms/step - loss: 2.4561 - accuracy: 0.2692 - val_loss: 2.0786 - val_accuracy: 0.0737\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 9s 172ms/step - loss: 1.5353 - accuracy: 0.4655 - val_loss: 2.0940 - val_accuracy: 0.0769\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 11s 212ms/step - loss: 1.1044 - accuracy: 0.6049 - val_loss: 2.0215 - val_accuracy: 0.1382\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 10s 206ms/step - loss: 0.8801 - accuracy: 0.6888 - val_loss: 1.9142 - val_accuracy: 0.2051\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 11s 210ms/step - loss: 0.6869 - accuracy: 0.7571 - val_loss: 1.7443 - val_accuracy: 0.3297\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 11s 215ms/step - loss: 0.5548 - accuracy: 0.8074 - val_loss: 1.5711 - val_accuracy: 0.4158\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 11s 224ms/step - loss: 0.4788 - accuracy: 0.8319 - val_loss: 1.3076 - val_accuracy: 0.5337\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 10s 201ms/step - loss: 0.3998 - accuracy: 0.8673 - val_loss: 1.1016 - val_accuracy: 0.6141\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 12s 233ms/step - loss: 0.3369 - accuracy: 0.8855 - val_loss: 0.7833 - val_accuracy: 0.7611\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 12s 236ms/step - loss: 0.3050 - accuracy: 0.8940 - val_loss: 0.5815 - val_accuracy: 0.8140\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor='accuracy', patience=2)\n",
    "]\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(X_train_final, Y_train_final, epochs=EPOCHS, batch_size=BATCH_SIZE,callbacks=callbacks_list, validation_data=(X_val, Y_val), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 1s 17ms/step - loss: 2.3780 - accuracy: 0.2075\n",
      "\n",
      "Accuracy on test data: 0.21\n",
      "\n",
      "Loss on test data: 2.38\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"\\nAccuracy on test data: %0.2f\" % score[1])\n",
    "print(\"\\nLoss on test data: %0.2f\" % score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Data augmentation reduces over-fitting but does not improve test accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
