{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Classfiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from random import randint\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the required models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.functional.Functional object at 0x13f881c00>\n",
      "<keras.engine.functional.Functional object at 0x14017af20>\n"
     ]
    }
   ],
   "source": [
    "# Loading the best face model\n",
    "face_model = keras.models.load_model('best_model_face_inception.h5')\n",
    "print(face_model)\n",
    "\n",
    "# Loading the best face model\n",
    "hand_model = keras.models.load_model('best_model_hand_molyswu.h5')\n",
    "print(hand_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the input and output datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 811 images belonging to 8 classes.\n",
      "21/21 [==============================] - 4s 122ms/step\n",
      "Found 526 images belonging to 8 classes.\n",
      "14/14 [==============================] - 8s 495ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nUnseen data (unextracted images)\\n'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# TODO: Need to make sure that the same image is used for both models\n",
    "FACE_DATA_PATH = '/Users/preshita/Desktop/unseen_face'\n",
    "HANDS_DATA_PATH = '/Users/preshita/Desktop/unseen_hand'\n",
    "\n",
    "# Computing predictions by the best face model\n",
    "face_test_generator = test_datagen.flow_from_directory(FACE_DATA_PATH,\n",
    "                                                    batch_size  = 40,\n",
    "                                                    class_mode  = 'categorical', \n",
    "                                                    target_size = (100, 75), shuffle = False)\n",
    "face_data_inputs = face_test_generator # Face data input\n",
    "y_face_preds = face_model.predict(face_test_generator) # Face data predictions\n",
    "\n",
    "# Computing predictions by the best hand model\n",
    "hand_test_generator = test_datagen.flow_from_directory(HANDS_DATA_PATH,\n",
    "                                                    batch_size  = 40,\n",
    "                                                    class_mode  = 'categorical', \n",
    "                                                    target_size = (100, 75), shuffle = False)\n",
    "hands_data_inputs = hand_test_generator # Hand data input\n",
    "y_hands_preds = hand_model.predict(hand_test_generator) # Hand data predictions\n",
    "\n",
    "# Expected data outputs\n",
    "expected_output_labels = face_test_generator.classes # Expected output labels, assuming that both models are working with the same images\n",
    "data_outputs = np.zeros((expected_output_labels.size, expected_output_labels.max() + 1))\n",
    "data_outputs[np.arange(expected_output_labels.size), expected_output_labels] = 1\n",
    "\n",
    "\n",
    "'''\n",
    "Unseen data (unextracted images)\n",
    "Note: Not to be used in final model\n",
    "'''\n",
    "# unseen_dir = '/Users/preshita/Desktop/combined_new/unseen'\n",
    "# unseen_test_generator = test_datagen.flow_from_directory(  unseen_dir,\n",
    "#                                                     batch_size  = 40,\n",
    "#                                                     class_mode  = 'categorical', \n",
    "#                                                     target_size = (100, 75), shuffle = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given an array contain the predictions from each classifier and the weights to be assigned to each classifier, this function computes the final weighted probability.\n",
    "'''\n",
    "def weighted_probability(num_of_classfiers, num_of_classes, networks_outputs, curr_weight_combi):\n",
    "    result = [0 for i in range(0, num_of_classes)]\n",
    "    sum = 0\n",
    "\n",
    "    for i in range(0, num_of_classfiers):\n",
    "        curr_network_output = networks_outputs[i]\n",
    "        curr_weight = curr_weight_combi[i]\n",
    "\n",
    "        for j in range(0, num_of_classes):\n",
    "            result[j] += curr_network_output[j] * curr_weight\n",
    "            sum += result[j]\n",
    "    \n",
    "    for k in range(0, num_of_classes): # Normalising to ensure that the final output is still in terms of probability\n",
    "        result[k] = result[k] / sum\n",
    "\n",
    "    return result\n",
    "\n",
    "'''\n",
    "Calculates the negative log loss.\n",
    "'''\n",
    "def fitness(y_pred, y_true): # Negative log loss function\n",
    "    return metrics.log_loss(y_true, y_pred)\n",
    "\n",
    "'''\n",
    "Randomly changes a given float number (up to 2%). \n",
    "Note: The method of mutation was not stated in the research paper. \n",
    "'''\n",
    "def mutate(weight_combi): #TODO: Need to double-check if this is okay\n",
    "    for i in range(0, len(weight_combi)):\n",
    "        weight_combi[i] = weight_combi[i] * random.uniform(0.99, 1.01)\n",
    "    \n",
    "    return weight_combi\n",
    "\n",
    "'''\n",
    "Given 2 different possible weight combination, this function produces a final weight combination by randomly extracting weight elements from either parent combinations.\n",
    "'''\n",
    "def cross_over(num_of_classifiers, parent_1, parent_2): #TODO: Need to double-check if this is okay\n",
    "    cut = random.randint(0, num_of_classifiers - 1)\n",
    "    new_weight_combi = parent_1[:cut] \n",
    "    new_weight_combi.extend(parent_2[cut:])\n",
    "\n",
    "    return new_weight_combi\n",
    "\n",
    "'''\n",
    "Produces combinations of weights that can be assigned to each of the classifiers. \n",
    "'''\n",
    "def generate_possible_weight_combis(num_of_classifiers, num_of_combis, weight_limit):\n",
    "    possible_weight_combis = []\n",
    "\n",
    "    while (num_of_combis > 0):\n",
    "        curr_weight_combi = []\n",
    "        curr_combi_len = 0\n",
    "\n",
    "        while (curr_combi_len < num_of_classifiers):\n",
    "            curr_weight = random.uniform(0, weight_limit)\n",
    "            curr_weight_combi.append(curr_weight)\n",
    "\n",
    "            curr_combi_len += 1\n",
    "        \n",
    "        possible_weight_combis.append(curr_weight_combi)\n",
    "        num_of_combis -= 1\n",
    "    \n",
    "    return possible_weight_combis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start of Genetic Algorithm to find the optimal weights for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98.18311664413463, 20.049923510498402], [38.120301118561386, 56.76694502503822], [94.84750112714451, 24.952625895181612], [55.49718926168366, 40.0650340518719], [98.8923690433, 75.49899789322473], [46.082826324988545, 12.620305329160232], [5.625216992778126, 9.02665109316011], [31.195921271450487, 22.631018932846324], [98.8923690433, 75.49899789322473], [98.8923690433, 1.5349448441986269], [46.082826324988545, 56.76694502503822], [46.082826324988545, 56.76694502503822], [46.082826324988545, 9.118041996066719], [46.082826324988545, 40.0650340518719], [67.98899298805543, 17.4197490604741], [98.8923690433, 75.49899789322473], [98.8923690433, 75.49899789322473], [56.359675160711184, 13.691257437338821], [98.8923690433, 79.54628349516884], [58.75018831096176, 9.02665109316011], [67.98899298805543, 9.02665109316011], [43.634300882555934, 5.051245821518724], [39.9477707544503, 5.051245821518724], [95.84716748340128, 22.631018932846324], [92.69462229408612, 5.54753594800853], [98.8923690433, 75.49899789322473], [64.12788404127835, 2.105767893800936], [5.625216992778126, 56.76694502503822], [31.195921271450487, 87.58826519028236], [66.58490374994302, 9.166530412921048], [95.71764008439122, 13.20491813139792], [18.57267922488631, 54.14254826942613], [67.98899298805543, 17.4197490604741], [31.195921271450487, 78.70969096439285], [38.120301118561386, 78.70969096439285], [94.84750112714451, 24.952625895181612], [67.98899298805543, 17.4197490604741], [56.359675160711184, 13.691257437338821], [79.90601281547771, 11.5504362712324], [31.195921271450487, 11.74603232514576], [84.36620640068871, 9.166530412921048], [39.9477707544503, 5.051245821518724], [43.634300882555934, 17.4197490604741], [71.74548083357354, 5.051245821518724], [31.195921271450487, 11.74603232514576], [46.082826324988545, 5.051245821518724], [43.70545449759181, 17.4197490604741], [58.75018831096176, 40.0650340518719], [38.120301118561386, 92.71734351736927], [31.195921271450487, 9.02665109316011], [66.58490374994302, 5.54753594800853], [95.71764008439122, 2.105767893800936], [43.70545449759181, 79.54628349516884], [84.36620640068871, 12.620305329160232], [30.009182649051226, 92.71734351736927], [18.57267922488631, 54.14254826942613], [95.71764008439122, 92.71734351736927], [14.955056471293249, 18.726830669872818], [79.90601281547771, 24.952625895181612], [78.97928428274685, 56.76694502503822], [79.90601281547771, 11.5504362712324], [5.625216992778126, 78.70969096439285], [46.082826324988545, 84.98906215728763], [67.98899298805543, 13.20491813139792], [98.8923690433, 75.49899789322473], [43.634300882555934, 12.620305329160232], [64.12788404127835, 2.105767893800936], [39.9477707544503, 17.4197490604741], [39.9477707544503, 5.051245821518724], [97.60461361922813, 78.70969096439285], [35.59007230905378, 56.76694502503822], [92.69462229408612, 1.5349448441986269], [95.71764008439122, 13.20491813139792], [38.120301118561386, 9.55664397344046], [43.634300882555934, 11.74603232514576], [98.8923690433, 75.49899789322473], [58.75018831096176, 9.02665109316011], [35.59007230905378, 56.76694502503822], [79.90601281547771, 11.5504362712324], [79.90601281547771, 11.5504362712324], [56.359675160711184, 13.691257437338821], [71.74548083357354, 22.631018932846324], [64.01334198768674, 9.118041996066719], [71.74548083357354, 78.70969096439285], [84.36620640068871, 9.118041996066719], [66.58490374994302, 5.54753594800853], [18.57267922488631, 79.54628349516884], [92.69462229408612, 9.55664397344046], [38.120301118561386, 5.54753594800853], [43.70545449759181, 79.54628349516884], [55.49718926168366, 9.166530412921048], [18.57267922488631, 54.14254826942613], [94.84750112714451, 1.5349448441986269], [97.60461361922813, 15.417190594542307], [30.009182649051226, 92.71734351736927], [92.69462229408612, 40.0650340518719], [5.625216992778126, 18.726830669872818], [71.74548083357354, 22.631018932846324], [98.8923690433, 2.105767893800936], [39.9477707544503, 5.051245821518724]]\n",
      "[[43.634300882555934, 5.051245821518724], [97.60461361922813, 15.417190594542307], [31.195921271450487, 11.74603232514576], [58.75018831096176, 15.417190594542307], [84.36620640068871, 5.54753594800853], [58.75018831096176, 9.02665109316011], [58.75018831096176, 9.02665109316011], [64.12788404127835, 2.105767893800936], [79.90601281547771, 5.047234591592855], [98.8923690433, 75.49899789322473], [95.71764008439122, 5.54753594800853], [97.60461361922813, 11.5504362712324], [39.9477707544503, 5.051245821518724], [79.90601281547771, 9.028941325335428], [64.12788404127835, 9.02665109316011], [95.71764008439122, 13.20491813139792], [64.00140761653702, 9.028941325335428], [39.9477707544503, 5.051245821518724], [46.082826324988545, 40.0650340518719], [98.8923690433, 75.49899789322473], [58.75018831096176, 5.54753594800853], [58.75018831096176, 5.047234591592855], [38.120301118561386, 56.76694502503822], [64.00140761653702, 5.051245821518724], [64.12788404127835, 9.166530412921048], [38.120301118561386, 56.76694502503822], [31.195921271450487, 5.54753594800853], [97.60461361922813, 15.417190594542307], [98.8923690433, 75.49899789322473], [39.9477707544503, 5.051245821518724], [39.71482161690459, 5.047234591592855], [55.49718926168366, 9.02665109316011], [92.69462229408612, 5.047234591592855], [39.71482161690459, 5.047234591592855], [79.90601281547771, 11.5504362712324], [31.195921271450487, 13.20491813139792], [38.120301118561386, 2.105767893800936], [64.12788404127835, 2.105767893800936], [46.082826324988545, 40.0650340518719], [79.90601281547771, 11.5504362712324], [98.8923690433, 79.54628349516884], [43.634300882555934, 9.02665109316011], [64.12788404127835, 2.105767893800936], [66.94034140450391, 9.223382228442354], [64.00140761653702, 9.028941325335428], [92.69462229408612, 5.54753594800853], [58.75018831096176, 15.417190594542307], [95.71764008439122, 5.051245821518724], [38.120301118561386, 56.76694502503822], [98.8923690433, 75.49899789322473], [39.9477707544503, 11.5504362712324], [39.9477707544503, 13.20491813139792], [39.9477707544503, 9.02665109316011], [39.71482161690459, 5.047234591592855], [46.082826324988545, 11.5504362712324], [43.634300882555934, 5.051245821518724], [55.49718926168366, 9.02665109316011], [39.71482161690459, 9.02665109316011], [79.90601281547771, 5.54753594800853], [31.195921271450487, 40.0650340518719], [55.49718926168366, 9.028941325335428], [58.75018831096176, 9.02665109316011], [64.12788404127835, 2.105767893800936], [95.71764008439122, 13.20491813139792], [98.8923690433, 11.5504362712324], [39.9477707544503, 5.051245821518724], [97.60461361922813, 22.631018932846324], [84.36620640068871, 75.49899789322473], [84.36620640068871, 75.49899789322473], [79.90601281547771, 11.5504362712324], [39.9477707544503, 12.620305329160232], [43.634300882555934, 5.051245821518724], [98.8923690433, 56.76694502503822], [66.94034140450391, 9.223382228442354], [98.8923690433, 75.49899789322473], [39.9477707544503, 5.051245821518724], [84.36620640068871, 13.20491813139792], [79.90601281547771, 9.028941325335428], [98.8923690433, 15.417190594542307], [55.49718926168366, 9.166530412921048], [79.90601281547771, 11.5504362712324], [97.60461361922813, 15.417190594542307], [71.74548083357354, 75.49899789322473], [95.71764008439122, 13.20491813139792], [38.120301118561386, 56.76694502503822], [71.74548083357354, 5.047234591592855], [95.71764008439122, 13.20491813139792], [39.9477707544503, 5.051245821518724], [84.36620640068871, 12.620305329160232], [79.90601281547771, 11.5504362712324], [39.9477707544503, 5.051245821518724], [64.00140761653702, 9.028941325335428], [31.195921271450487, 2.105767893800936], [92.69462229408612, 9.02665109316011], [64.00140761653702, 22.631018932846324], [55.49718926168366, 40.0650340518719], [31.195921271450487, 2.105767893800936], [43.634300882555934, 5.051245821518724], [58.75018831096176, 40.0650340518719], [39.71482161690459, 79.54628349516884]]\n",
      "[[95.71764008439122, 5.047234591592855], [66.94034140450391, 9.223382228442354], [39.71482161690459, 5.047234591592855], [39.9477707544503, 9.223382228442354], [39.9477707544503, 9.028941325335428], [95.71764008439122, 5.047234591592855], [98.8923690433, 11.5504362712324], [38.47480404048494, 2.12233357547206], [39.71482161690459, 5.051245821518724], [39.9477707544503, 2.1116659927453605], [39.76557579921074, 9.02665109316011], [64.00140761653702, 56.76694502503822], [95.71764008439122, 11.5504362712324], [39.76557579921074, 5.062146341921641], [39.9477707544503, 5.051245821518724], [71.74548083357354, 5.051245821518724], [63.74307455201143, 2.1116659927453605], [95.71764008439122, 2.1116659927453605], [66.94034140450391, 5.051245821518724], [39.9477707544503, 9.02665109316011], [95.71764008439122, 5.051245821518724], [39.71482161690459, 9.02665109316011], [63.74307455201143, 2.1116659927453605], [64.00140761653702, 9.028941325335428], [66.94034140450391, 9.223382228442354], [39.9477707544503, 9.223382228442354], [95.71764008439122, 2.105767893800936], [97.60461361922813, 2.1116659927453605], [39.9477707544503, 5.047234591592855], [38.120301118561386, 5.047234591592855], [63.74307455201143, 9.028941325335428], [39.9477707544503, 11.5504362712324], [64.00140761653702, 13.20491813139792], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.051245821518724], [97.60461361922813, 13.20491813139792], [38.47480404048494, 2.12233357547206], [71.74548083357354, 75.49899789322473], [39.9477707544503, 9.02665109316011], [95.71764008439122, 5.051245821518724], [39.9477707544503, 9.028941325335428], [95.71764008439122, 13.20491813139792], [39.9477707544503, 5.051245821518724], [43.634300882555934, 5.051245821518724], [95.71764008439122, 2.12233357547206], [39.9477707544503, 5.051245821518724], [39.9477707544503, 56.76694502503822], [38.120301118561386, 56.76694502503822], [64.00140761653702, 2.1116659927453605], [98.8923690433, 11.5504362712324], [39.9477707544503, 5.051245821518724], [39.71482161690459, 2.12233357547206], [39.9477707544503, 13.20491813139792], [64.12788404127835, 2.105767893800936], [66.94034140450391, 9.223382228442354], [66.94034140450391, 9.028941325335428], [43.634300882555934, 5.051245821518724], [95.71764008439122, 9.02665109316011], [66.94034140450391, 9.223382228442354], [66.94034140450391, 9.223382228442354], [39.71482161690459, 13.20491813139792], [63.74307455201143, 5.062146341921641], [64.00140761653702, 5.051245821518724], [39.9477707544503, 5.051245821518724], [43.634300882555934, 5.051245821518724], [38.120301118561386, 56.76694502503822], [63.74307455201143, 5.051245821518724], [95.71764008439122, 13.20491813139792], [98.8923690433, 11.5504362712324], [95.71764008439122, 9.02665109316011], [39.71482161690459, 5.051245821518724], [39.9477707544503, 5.051245821518724], [39.9477707544503, 11.5504362712324], [71.74548083357354, 5.047234591592855], [39.9477707544503, 5.051245821518724], [95.71764008439122, 13.20491813139792], [39.71482161690459, 5.047234591592855], [95.71764008439122, 13.20491813139792], [39.76557579921074, 5.062146341921641], [95.71764008439122, 5.051245821518724], [39.71482161690459, 9.02665109316011], [64.12788404127835, 5.051245821518724], [39.9477707544503, 2.12233357547206], [39.9477707544503, 5.051245821518724], [38.120301118561386, 9.223382228442354], [95.71764008439122, 13.20491813139792], [64.00140761653702, 5.051245821518724], [39.9477707544503, 5.051245821518724], [98.8923690433, 5.051245821518724], [39.71482161690459, 5.051245821518724], [64.12788404127835, 2.105767893800936], [95.71764008439122, 9.223382228442354], [38.47480404048494, 9.02665109316011], [97.60461361922813, 11.5504362712324], [39.9477707544503, 5.051245821518724], [38.120301118561386, 56.76694502503822], [95.71764008439122, 5.051245821518724], [39.71482161690459, 5.051245821518724], [97.60461361922813, 11.5504362712324], [71.74548083357354, 75.49899789322473]]\n",
      "[[39.9477707544503, 5.047234591592855], [39.9477707544503, 5.051245821518724], [39.76557579921074, 9.223382228442354], [39.9477707544503, 5.020427015508424], [40.00366692709235, 5.075403853140151], [98.8923690433, 5.051245821518724], [39.9477707544503, 5.047234591592855], [39.9477707544503, 5.047234591592855], [39.9477707544503, 5.047234591592855], [39.71482161690459, 5.051245821518724], [40.00366692709235, 5.075403853140151], [39.71482161690459, 5.051245821518724], [39.9477707544503, 5.047234591592855], [64.00140761653702, 11.5504362712324], [39.9477707544503, 56.76694502503822], [98.13763165320043, 11.625282714005177], [39.76542056158315, 5.020427015508424], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.051245821518724], [66.94034140450391, 9.223382228442354], [64.00140761653702, 9.223382228442354], [39.9477707544503, 5.047234591592855], [39.9477707544503, 11.5504362712324], [97.60461361922813, 9.223382228442354], [97.60461361922813, 5.047234591592855], [39.9477707544503, 9.223382228442354], [39.9477707544503, 11.5504362712324], [39.9477707544503, 5.075403853140151], [98.8923690433, 11.5504362712324], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.051245821518724], [39.9477707544503, 9.02665109316011], [95.71764008439122, 5.075403853140151], [66.94034140450391, 9.223382228442354], [98.13763165320043, 2.1116659927453605], [97.60461361922813, 11.5504362712324], [39.9477707544503, 5.051245821518724], [39.71482161690459, 5.051245821518724], [39.9477707544503, 5.051245821518724], [66.94034140450391, 11.5504362712324], [39.71482161690459, 11.5504362712324], [39.9477707544503, 9.223382228442354], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.047234591592855], [39.9477707544503, 5.051245821518724], [66.94034140450391, 9.223382228442354], [39.9477707544503, 5.047234591592855], [66.94034140450391, 2.12233357547206], [39.9477707544503, 11.5504362712324], [38.47480404048494, 2.12233357547206], [39.76557579921074, 11.5504362712324], [40.00366692709235, 5.075403853140151], [98.13763165320043, 11.625282714005177], [39.9477707544503, 5.051245821518724], [97.60461361922813, 5.051245821518724], [39.9477707544503, 5.051245821518724], [39.71482161690459, 5.051245821518724], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.047234591592855], [66.94034140450391, 9.223382228442354], [97.60461361922813, 11.5504362712324], [64.00140761653702, 2.1116659927453605], [64.00140761653702, 2.1116659927453605], [39.76542056158315, 5.020427015508424], [98.8923690433, 11.5504362712324], [40.00366692709235, 2.1116659927453605], [39.9477707544503, 5.051245821518724], [39.9477707544503, 9.02665109316011], [39.9477707544503, 5.051245821518724], [66.94034140450391, 5.047234591592855], [64.00140761653702, 56.76694502503822], [64.00140761653702, 56.76694502503822], [39.9477707544503, 5.020427015508424], [64.00140761653702, 2.1116659927453605], [39.9477707544503, 5.051245821518724], [64.00140761653702, 5.051245821518724], [39.9477707544503, 5.020427015508424], [39.9477707544503, 56.76694502503822], [64.00140761653702, 56.76694502503822], [98.8923690433, 11.5504362712324], [39.9477707544503, 11.5504362712324], [98.8923690433, 11.5504362712324], [40.00366692709235, 5.051245821518724], [39.9477707544503, 9.02665109316011], [39.76542056158315, 11.5504362712324], [95.71764008439122, 11.5504362712324], [39.76542056158315, 11.5504362712324], [39.9477707544503, 11.5504362712324], [98.13763165320043, 11.625282714005177], [64.00140761653702, 5.051245821518724], [66.94034140450391, 9.223382228442354], [97.60461361922813, 11.5504362712324], [39.76557579921074, 13.20491813139792], [98.8923690433, 5.051245821518724], [97.60461361922813, 11.5504362712324], [66.94034140450391, 5.047234591592855], [97.60461361922813, 9.223382228442354], [97.60461361922813, 5.051245821518724], [39.76542056158315, 5.020427015508424], [97.60461361922813, 11.5504362712324]]\n",
      "[[39.9477707544503, 5.051245821518724], [66.94034140450391, 9.223382228442354], [39.870169714383316, 5.020427015508424], [39.76542056158315, 5.075403853140151], [39.9477707544503, 5.051245821518724], [98.13763165320043, 5.066262410648761], [39.9477707544503, 5.051245821518724], [66.94034140450391, 9.223382228442354], [39.71482161690459, 5.051245821518724], [98.8923690433, 5.014390942999182], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.051245821518724], [40.00366692709235, 5.075403853140151], [66.94034140450391, 9.223382228442354], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.051245821518724], [39.759517545573694, 11.625282714005177], [39.9477707544503, 5.020427015508424], [40.00366692709235, 9.223382228442354], [39.759517545573694, 5.066262410648761], [39.9477707544503, 5.051245821518724], [40.00366692709235, 5.075403853140151], [39.9477707544503, 5.075403853140151], [97.60461361922813, 5.070778802738119], [98.8923690433, 5.051245821518724], [98.8923690433, 9.223382228442354], [40.00366692709235, 5.075403853140151], [39.9477707544503, 5.047234591592855], [39.76557579921074, 9.223382228442354], [39.9477707544503, 5.070778802738119], [39.9477707544503, 5.051245821518724], [40.00366692709235, 5.075403853140151], [98.8923690433, 5.051245821518724], [39.71482161690459, 5.051245821518724], [39.76557579921074, 9.223382228442354], [39.870169714383316, 5.070778802738119], [39.9477707544503, 5.020427015508424], [39.76542056158315, 5.020427015508424], [39.9477707544503, 5.051245821518724], [39.76557579921074, 5.014390942999182], [39.76542056158315, 5.075403853140151], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.047234591592855], [97.60461361922813, 5.047234591592855], [39.9477707544503, 5.051245821518724], [39.759517545573694, 5.066262410648761], [39.76557579921074, 5.020427015508424], [40.00366692709235, 9.223382228442354], [39.9477707544503, 11.625282714005177], [39.9477707544503, 5.014390942999182], [39.9477707544503, 5.051245821518724], [39.71482161690459, 5.051245821518724], [98.13763165320043, 5.051245821518724], [98.8923690433, 5.070778802738119], [39.76542056158315, 5.020427015508424], [39.9477707544503, 5.051245821518724], [39.76542056158315, 5.020427015508424], [39.9477707544503, 5.047234591592855], [39.9477707544503, 5.051245821518724], [98.13763165320043, 5.070778802738119], [39.9477707544503, 5.020427015508424], [98.8923690433, 9.223382228442354], [66.94034140450391, 9.223382228442354], [39.9477707544503, 5.051245821518724], [39.870169714383316, 5.070778802738119], [39.9477707544503, 5.020427015508424], [39.76542056158315, 5.066262410648761], [66.94034140450391, 5.051245821518724], [39.870169714383316, 5.014390942999182], [39.76542056158315, 5.051245821518724], [98.13763165320043, 11.625282714005177], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.051245821518724], [39.9477707544503, 9.223382228442354], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.051245821518724], [39.9477707544503, 9.223382228442354], [39.9477707544503, 5.075403853140151], [40.00366692709235, 5.075403853140151], [39.9477707544503, 9.223382228442354], [39.76542056158315, 5.020427015508424], [98.13763165320043, 11.625282714005177], [39.9477707544503, 9.223382228442354], [40.00366692709235, 5.047234591592855], [66.94034140450391, 9.223382228442354], [39.9477707544503, 9.223382228442354], [39.71482161690459, 5.051245821518724], [39.9477707544503, 5.051245821518724], [39.9477707544503, 5.047234591592855], [39.54221014560623, 5.051245821518724], [39.870169714383316, 5.070778802738119], [66.94034140450391, 5.075403853140151], [39.71482161690459, 5.051245821518724], [66.94034140450391, 9.223382228442354], [39.9477707544503, 5.020427015508424], [39.759517545573694, 5.066262410648761]]\n",
      "The best weight combination is: [39.54221014560623, 5.051245821518724]\n",
      "The fitness score of this combination is: 0.3426269564502407\n"
     ]
    }
   ],
   "source": [
    "# Defining essential variables\n",
    "num_of_classifiers = 2\n",
    "num_of_classes = 8\n",
    "num_of_required_weight_combis = 100\n",
    "weight_limit = 100\n",
    "possible_weight_combis = generate_possible_weight_combis(num_of_classifiers, num_of_required_weight_combis, weight_limit)\n",
    "max_num_of_iters = 5\n",
    "\n",
    "# print(possible_weight_combis)\n",
    "\n",
    "while (max_num_of_iters > 0):\n",
    "    # Step 1: Randomly chossing 50% of the dataset to calculate the fitness scores for\n",
    "    chosen_y_true = []\n",
    "    chosen_y_face_pred = []\n",
    "    chosen_y_hand_pred = []\n",
    "\n",
    "    required_num_of_samples = len(data_outputs) // 2 # Rounding down\n",
    "\n",
    "    random_indices = []\n",
    "    while required_num_of_samples > 0:\n",
    "        # curr_index = randint(0, len(data_outputs) - 1)\n",
    "        curr_index = randint(0, 525) # TODO: Temporary work around\n",
    "\n",
    "        if (curr_index not in random_indices):\n",
    "            chosen_y_true.append(data_outputs[curr_index])\n",
    "            chosen_y_face_pred.append(y_face_preds[curr_index])\n",
    "            chosen_y_hand_pred.append(y_hands_preds[curr_index])\n",
    "\n",
    "            random_indices.append(curr_index)\n",
    "            required_num_of_samples -= 1\n",
    "\n",
    "    # Step 2: Calculate the average fitness scores for each of the possible weight combinations\n",
    "    fitness_and_weights = []\n",
    "\n",
    "    for weights in possible_weight_combis:\n",
    "        accumulated_fitness_score = 0\n",
    "        num_of_samples = 0\n",
    "\n",
    "        for i in range(0, len(chosen_y_true)):\n",
    "            network_outputs = [chosen_y_face_pred[i], chosen_y_hand_pred[i]]\n",
    "            y_pred = weighted_probability(num_of_classifiers, num_of_classes, network_outputs, weights)\n",
    "            y_true = chosen_y_true[i]\n",
    "            fitness_score = fitness(y_pred, y_true)\n",
    "            accumulated_fitness_score += fitness_score\n",
    "\n",
    "            num_of_samples += 1\n",
    "        \n",
    "        avg_fitness_score = accumulated_fitness_score / num_of_samples\n",
    "        fitness_and_weights.append((avg_fitness_score, weights))\n",
    "    \n",
    "    # print(fitness_and_weights) # For testing\n",
    "\n",
    "    # Step 3: Rank the weight combis from best to worse\n",
    "    fitness_and_weights.sort() # The combis with the lowest log loss is at the start\n",
    "    # print(fitness_and_weights) # For testing\n",
    "\n",
    "    # Step 4: Selecting parents\n",
    "    parents = []\n",
    "    curr_index = 0\n",
    "\n",
    "    # Selecting top 20% of the weight combis\n",
    "    top_20_percent = int(len(fitness_and_weights) // 5) # Rounding down\n",
    "    while (top_20_percent > 0):\n",
    "        parents.append(fitness_and_weights[curr_index][1])\n",
    "        top_20_percent -= 1\n",
    "        curr_index += 1\n",
    "\n",
    "    # Randomly choosing another 10% of the weight combinations\n",
    "    another_10_percent = int(len(fitness_and_weights) // 10)  # Rounding down\n",
    "    while(another_10_percent > 0):\n",
    "        random_score_and_parent = random.choice(fitness_and_weights[curr_index:])\n",
    "        parents.append(random_score_and_parent[1])\n",
    "        fitness_and_weights.remove(random_score_and_parent)\n",
    "\n",
    "        another_10_percent -= 1\n",
    "    \n",
    "    # print(parents) # For testing\n",
    "\n",
    "    # Step 5: Randomly mutate 5% of the selected parents\n",
    "    num_of_parents_to_mutate = max(1, int(len(parents) // 10))  # Rounding down\n",
    "    index_of_parents_to_mutate = [random.randint(0, len(parents) - 1) for i in range(0, num_of_parents_to_mutate)]\n",
    "\n",
    "    for index in index_of_parents_to_mutate:\n",
    "        parents[index] = mutate(parents[index])\n",
    "    \n",
    "    # print(parents) # For testing\n",
    "\n",
    "    # Step 6: Randomly cross over parents to produce new set of weight combinations\n",
    "    new_weight_combis = []\n",
    "    index_of_crossed_parents = []\n",
    "    num_of_curr_weights = 0\n",
    "\n",
    "    while (num_of_curr_weights < num_of_required_weight_combis):\n",
    "        chosen_parents = (random.randint(0, len(parents) - 1), random.randint(0, len(parents) - 1))\n",
    "        parent_1 = parents[chosen_parents[0]]\n",
    "        parent_2 = parents[chosen_parents[1]]\n",
    "\n",
    "        if (parent_1 != parent_2 and chosen_parents not in index_of_crossed_parents):\n",
    "            new_weight_combi = cross_over(num_of_classifiers, parent_1, parent_2)\n",
    "            new_weight_combis.append(new_weight_combi)\n",
    "            num_of_curr_weights += 1\n",
    "\n",
    "    possible_weight_combis = new_weight_combis\n",
    "    print(possible_weight_combis) # For testing\n",
    "\n",
    "    max_num_of_iters -= 1\n",
    "\n",
    "# Step 7: Select the best weights combination\n",
    "final_fitness_and_weights = []\n",
    "\n",
    "for weights in possible_weight_combis:\n",
    "    accumulated_fitness_score = 0\n",
    "    num_of_samples = 0\n",
    "\n",
    "    for i in range(0, len(chosen_y_true)):\n",
    "            network_outputs = [chosen_y_face_pred[i], chosen_y_hand_pred[i]]\n",
    "            y_pred = weighted_probability(num_of_classifiers, num_of_classes, network_outputs, weights)\n",
    "            y_true = chosen_y_true[i]\n",
    "            fitness_score = fitness(y_pred, y_true)\n",
    "            accumulated_fitness_score += fitness_score\n",
    "\n",
    "            num_of_samples += 1\n",
    "    \n",
    "    avg_fitness_score = accumulated_fitness_score / num_of_samples\n",
    "    final_fitness_and_weights.append((avg_fitness_score, weights))\n",
    "\n",
    "final_fitness_and_weights.sort() # The combis with the lowest log loss is at the start\n",
    "best_weights = final_fitness_and_weights[0][1]\n",
    "print(\"The best weight combination is: \" + str(best_weights))\n",
    "print(\"The fitness score of this combination is: \" + str(final_fitness_and_weights[0][0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the performance of the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.150190\n",
      "Precision: 0.120289\n",
      "Recall: 0.150190\n",
      "F1 score: 0.117254\n"
     ]
    }
   ],
   "source": [
    "weighted_preds = []\n",
    "\n",
    "# for i in range(0, len(expected_output_labels)):\n",
    "for i in range(0, 526): # TODO: Temporary work around\n",
    "    networks_outputs = [y_face_preds[i], y_hands_preds[i]]\n",
    "    weighted_preds.append(weighted_probability(num_of_classifiers, num_of_classes, networks_outputs, best_weights))\n",
    "\n",
    "ensemble_ypred = np.argmax(weighted_preds, axis=1)\n",
    "\n",
    "expected_output_labels = hand_test_generator.classes\n",
    "\n",
    "# Printing out metrics\n",
    "accuracy = accuracy_score(expected_output_labels, ensemble_ypred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(expected_output_labels, ensemble_ypred, average='weighted')\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(expected_output_labels, ensemble_ypred, average='weighted')\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(expected_output_labels, ensemble_ypred, average='weighted')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type 3: Random forests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
